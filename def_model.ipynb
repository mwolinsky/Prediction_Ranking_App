{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0dba848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3911c2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Colocamos el lugar de donde extraer el csv\n",
    "data_location= 'https://raw.githubusercontent.com/mwolinsky/Ranking_predictor/main/england-premier-league-players-2018-to-2019-stats.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d658f52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leemos el csv con lo jugadores como indice\n",
    "df= pd.read_csv(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68e2eebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#!pip install imbalanced-learn\n",
    "\n",
    "#Colocamos el lugar de donde extraer el csv\n",
    "data_location= 'https://raw.githubusercontent.com/mwolinsky/Ranking_predictor/main/england-premier-league-players-2018-to-2019-stats.csv'\n",
    "\n",
    "#Leemos el csv con lo jugadores como indice\n",
    "df= pd.read_csv(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c70f32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_def=df[df.position==\"Defender\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd131ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c81b05f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-40-3287282ed513>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_def[\"min_per_total_match\"]=df_def.minutes_played_overall/(38*90)\n"
     ]
    }
   ],
   "source": [
    "df_def[\"min_per_total_match\"]=df_def.minutes_played_overall/(38*90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "49707506",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_def= df_def.replace(-1,99999) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c96dbf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_def['top_rank']=df_def.loc[:,['rank_in_league_top_attackers','rank_in_league_top_midfielders','rank_in_league_top_defenders']].apply(lambda x: x.min(),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dcfe7ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns=['position','Current Club','nationality']\n",
    "for column in categorical_columns:\n",
    "    dummies = pd.get_dummies(df_def[column], prefix=column,drop_first=True)\n",
    "    df_def = pd.concat([df_def, dummies], axis=1)\n",
    "    df_def = df_def.drop(columns=column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d9cf2715",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_def['top_def_15']=df.rank_in_league_top_defenders.apply(lambda x: 1 if x>0 and x<=15 else 0)\n",
    "df_def['top_15']= df_def.apply(lambda x: 1 if x.top_def_15==1 else 0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "802c99ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.loc[:,[min_per_conceded_overall,conceded_per_90_overall,minutes_played_overall,\"goals_overall\",\"clean_sheets_away\"]]\n",
    "y= df.top_15\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Con estratificaci칩n en y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,random_state=162)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train),columns=X_train.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test),columns=X_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "37ee52dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[19:12:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "{'subsample': 0.5, 'n_estimators': 100, 'max_depth': 15, 'learning_rate': 0.3, 'colsample_bytree': 0.8999999999999999, 'colsample_bylevel': 0.4}\n",
      "Cross-validation score: 1.0\n",
      "Test score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "model_xg = XGBClassifier(n_jobs=-1, use_label_encoder=False)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, random_state=41, shuffle=True)\n",
    "\n",
    "#Hacemos un Grid Search para optimizar hiperpar치metros\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "params = { 'max_depth': [3, 5, 6, 10, 15, 20],\n",
    "           'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "           'subsample': np.arange(0.5, 1.0, 0.1),\n",
    "           'colsample_bytree': np.arange(0.4, 1.0, 0.1),\n",
    "           'colsample_bylevel': np.arange(0.4, 1.0, 0.1),\n",
    "           'n_estimators': [100, 500, 1000]}\n",
    "\n",
    "clf = RandomizedSearchCV(model_xg, param_distributions=params, cv=cv, verbose=1, n_jobs=-1,random_state=2123,)\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "print(clf.best_params_)\n",
    "\n",
    "cv_score = clf.best_score_\n",
    "test_score = clf.score(X_test, y_test)\n",
    "print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b70d8357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:12:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "El valor del AUC es:  0.9888888888888888\n",
      "El accuracy es: 0.9791666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maty\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#Entrenamos el modelo con los mejores hiperpar치metros\n",
    "xgb = XGBClassifier(subsample= 0.8999999999999999,n_estimators=100, max_depth=6, learning_rate= 0.1,colsample_bytree= 0.6, colsample_bylevel= 0.7999999999999999)\n",
    "xgb.fit(X_train, y_train)\n",
    "#Testeamos el modelo con los hiperpar치metros tuneados\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "xgb_auc = roc_auc_score(y_test, xgb.predict(X_test))\n",
    "\n",
    "print(\"El valor del AUC es: \", xgb_auc)\n",
    "print('El accuracy es:', accuracy_score(y_test, xgb.predict(X_test)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f5c2dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>minutes_played_overall</td>\n",
       "      <td>0.174274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>min_per_conceded_overall</td>\n",
       "      <td>0.154645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Current Club_Liverpool</td>\n",
       "      <td>0.133427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>minutes_played_away</td>\n",
       "      <td>0.124942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>yellow_cards_overall</td>\n",
       "      <td>0.107111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Current Club_Manchester City</td>\n",
       "      <td>0.059730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>clean_sheets_overall</td>\n",
       "      <td>0.053742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>clean_sheets_home</td>\n",
       "      <td>0.053060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>conceded_per_90_overall</td>\n",
       "      <td>0.039841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>goals_per_90_home</td>\n",
       "      <td>0.017600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        features  importance\n",
       "2         minutes_played_overall    0.174274\n",
       "31      min_per_conceded_overall    0.154645\n",
       "49        Current Club_Liverpool    0.133427\n",
       "4            minutes_played_away    0.124942\n",
       "22          yellow_cards_overall    0.107111\n",
       "50  Current Club_Manchester City    0.059730\n",
       "16          clean_sheets_overall    0.053742\n",
       "17             clean_sheets_home    0.053060\n",
       "30       conceded_per_90_overall    0.039841\n",
       "27             goals_per_90_home    0.017600"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance_xgb=pd.DataFrame({'features': X.columns,'importance':xgb.feature_importances_}).sort_values(by='importance',ascending=False)\n",
    "\n",
    "importance_xgb.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0c5a0667",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_def['min_per_conceded_overall']= df.min_per_conceded_overall/38\n",
    "df_def['minutes_played_overall']= df.minutes_played_overall/38\n",
    "df_def['goals_overall']= df.goals_overall/38\n",
    "df_def[\"clean_sheets_away\"]=df_def.clean_sheets_away/19\n",
    "\n",
    "df_def[\"goals_involved_per_90_overall\"]=df_def.goals_involved_per_90_overall/38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "07a119bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[19:42:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "{'subsample': 0.5, 'n_estimators': 100, 'max_depth': 15, 'learning_rate': 0.3, 'colsample_bytree': 0.8999999999999999, 'colsample_bylevel': 0.4}\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state = 11)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "model_xg = XGBClassifier(n_jobs=-1, use_label_encoder=False)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, random_state=41, shuffle=True)\n",
    "\n",
    "#Hacemos un Grid Search para optimizar hiperpar치metros\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "params = { 'max_depth': [3, 5, 6, 10, 15, 20],\n",
    "           'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "           'subsample': np.arange(0.5, 1.0, 0.1),\n",
    "           'colsample_bytree': np.arange(0.4, 1.0, 0.1),\n",
    "           'colsample_bylevel': np.arange(0.4, 1.0, 0.1),\n",
    "           'n_estimators': [100, 500, 1000]}\n",
    "\n",
    "clf = RandomizedSearchCV(model_xg, param_distributions=params, cv=cv, verbose=1, n_jobs=-1,random_state=2123,)\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "print(clf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cb7df141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:42:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "El valor del AUC es:  0.9888888888888888\n",
      "El accuracy es: 0.9791666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maty\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(subsample= 0.5,n_estimators=100, max_depth=15, learning_rate= 0.3,colsample_bytree= 0.8999, colsample_bylevel= 0.4)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "xgb_auc = roc_auc_score(y_test, xgb.predict(X_test))\n",
    "\n",
    "print(\"El valor del AUC es: \", xgb_auc)\n",
    "print('El accuracy es:', accuracy_score(y_test, xgb.predict(X_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5255c12e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>min_per_conceded_overall</td>\n",
       "      <td>0.403257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>conceded_per_90_overall</td>\n",
       "      <td>0.157069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>minutes_played_overall</td>\n",
       "      <td>0.145273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Current Club_Manchester City</td>\n",
       "      <td>0.091529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>goals_overall</td>\n",
       "      <td>0.079715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>clean_sheets_away</td>\n",
       "      <td>0.043778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>conceded_away</td>\n",
       "      <td>0.021856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>goals_involved_per_90_overall</td>\n",
       "      <td>0.020706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>clean_sheets_overall</td>\n",
       "      <td>0.018265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>assists_home</td>\n",
       "      <td>0.014521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         features  importance\n",
       "31       min_per_conceded_overall    0.403257\n",
       "30        conceded_per_90_overall    0.157069\n",
       "2          minutes_played_overall    0.145273\n",
       "50   Current Club_Manchester City    0.091529\n",
       "8                   goals_overall    0.079715\n",
       "18              clean_sheets_away    0.043778\n",
       "21                  conceded_away    0.021856\n",
       "24  goals_involved_per_90_overall    0.020706\n",
       "16           clean_sheets_overall    0.018265\n",
       "12                   assists_home    0.014521"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance_xgb=pd.DataFrame({'features': X.columns,'importance':xgb.feature_importances_}).sort_values(by='importance',ascending=False)\n",
    "\n",
    "importance_xgb.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ed8d98ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004009330806239977"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df_def.clean_sheets_away)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e5e52d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb.save_model(\"model_def.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
